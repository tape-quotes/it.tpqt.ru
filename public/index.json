
[{"content":"Устанавливаем пакеты:\ndnf install -y iscsi-initiator-utils device-mapper-multipath Уточняем имя инициатора (IQN):\ncat /etc/iscsi/initiatorname.iscsi или записываем в файл собственное вида:\nInitiatorName=iqn.2024-08.com.itglobal.bareos-aio-kz:bareos-sd01\nГенерируем дефолтный конфиг для multipath:\n/sbin/mpathconf --enable Вносим параметры авторизации в файл конфигурации\nvi /etc/iscsi/iscsid.conf Пояснения:\nUsername обычно совпадает с InitiatorName хоста.\nПриписка _in обозначает initiator.\nБез приписки _in - target или outgoing.\nnode.session.auth.authmethod = CHAP node.session.auth.chap_algs = SHA3-256,SHA256,SHA1,MD5 node.session.auth.username = iqn.1994-05.com.redhat:123123123 node.session.auth.password = target_pass node.session.auth.username_in = iqn.1994-05.com.redhat:123123123 node.session.auth.password_in = initiator_pass discovery.sendtargets.auth.authmethod = CHAP discovery.sendtargets.auth.username = iqn.1994-05.com.redhat:123123123 discovery.sendtargets.auth.password = target_pass discovery.sendtargets.auth.username_in = iqn.1994-05.com.redhat:123123123 discovery.sendtargets.auth.password_in = initiator_pass Включаем сервисы и проверяем логи на наличие ошибок:\nsystemctl enable --now iscsid \u0026amp;\u0026amp; systemctl enable --now multipathd systemctl status iscsid systemctl status multipathd Обнаруживаем точки входа к хранилищу:\niscsiadm -m discovery -t sendtargets -p \u0026lt;IP address\u0026gt; Подключаемся к обнаруженным узлам:\niscsiadm -m node --login (или подключаемся к каждому узлу хранилища, обнаруженному ранее:)\niscsiadm -m node --targetname \u0026#39;iqn.2002-09.com.lenovo:thinksystem.6d039ea0002cf17c00000000616ead3f\u0026#39; --portal \u0026#39;10.32.45.206\u0026#39; --login iscsiadm -m node --targetname \u0026#39;iqn.2002-09.com.lenovo:thinksystem.6d039ea0002cf17c00000000616ead3f\u0026#39; --portal \u0026#39;10.32.45.207\u0026#39; --login iscsiadm -m node --targetname \u0026#39;iqn.2002-09.com.lenovo:thinksystem.6d039ea0002cf17c00000000616ead3f\u0026#39; --portal \u0026#39;10.32.45.208\u0026#39; --login iscsiadm -m node --targetname \u0026#39;iqn.2002-09.com.lenovo:thinksystem.6d039ea0002cf17c00000000616ead3f\u0026#39; --portal \u0026#39;10.32.45.209\u0026#39; --login Проверяем, что выданный на хранилище диск доступен:\nmultipath -ll Пример вывода:\nmpatha (36d039ea0000016710000027f66b5e2ef) dm-2 NETAPP,INF-01-00 size=2.0T features=\u0026#39;3 queue_if_no_path pg_init_retries 50\u0026#39; hwhandler=\u0026#39;1 alua\u0026#39; wp=rw |-+- policy=\u0026#39;service-time 0\u0026#39; prio=50 status=active | |- 36:0:0:1 sde 8:64 active ready running | - 35:0:0:1 sdd 8:48 active ready running -+- policy=\u0026#39;service-time 0\u0026#39; prio=10 status=enabled |- 34:0:0:1 sdc 8:32 active ready running - 33:0:0:1 sdb 8:16 active ready running Полученное блочное устройство будет доступно по пути /dev/mapper/mpath[a..n]\nРазметить получившийся диск средствами lvm2 можно так:\npvcreate /dev/mapper/mpatha vgcreate data_vg /dev/mapper/mpatha lvcreate -L 1GiB --name data_lv data_vg /dev/mapper/mpatha lvextend /dev/mapper/data_vg-data_lv -l +100%FREE Параметры монтирования для /etc/fstab:\n/dev/mapper/mpatha /data/miniovol xfs _netdev,defaults 0 0 При флуде в логи со стороны multipathd вида:\nFeb 18 12:49:33 test-w1-k8s multipathd[32939]: sda: add missing path Feb 18 12:49:33 test-w1-k8s multipathd[32939]: sda: failed to get udev uid: Invalid argument Feb 18 12:49:33 test-w1-k8s multipathd[32939]: sda: failed to get sysfs uid: Invalid argument Feb 18 12:49:33 test-w1-k8s multipathd[32939]: sda: failed to get sgio uid: No such file or directory необходимо добавить в /etc/multipath.conf в блок blacklist:\nblacklist { device { vendor \u0026#34;VMware\u0026#34; product \u0026#34;Virtual disk\u0026#34; } } Увеличение размера тома после увеличения размера LUN:\nlsblk for i in b c d e; do echo 1 \u0026gt; /sys/block/sd$i/device/rescan; done multipathd resize map mpatha pvresize /dev/mapper/mpatha lvextend /dev/repo_low_hdd_vg/low_hdd01 -l +100%FREE xfs_growfs /dev/repo_low_hdd_vg/low_hdd01 ","date":"12 августа 2024","externalUrl":null,"permalink":"/posts/linux-iscsi-multipathd-lvm/","section":"Posts","summary":"","title":"Настройка iSCSI, multipathd и lvm в EL9","type":"posts"},{"content":"или \u0026ldquo;Как потратить драгоценное время зря, чтобы объяснить разрабу, что это он\u0026hellip;\n\u0026hellip;не прав\u0026rdquo;.\nOneline-команда # openssl s_client -connect 127.0.0.1:9101 -cipher ECDHE-PSK-CHACHA20-POLY1305 \\ -psk_identity \u0026#34;R_CONSOLE`echo -n -e \u0026#34;\\x1e\u0026#34;`*UserAgent*\u0026#34; \\ -psk `echo -n \u0026#34;30b5246d003966329927\u0026#34; | md5sum | awk {\u0026#39;print $1\u0026#39;} | tr -d \u0026#39;\\n\u0026#39;|\\ xxd -p | tr -d \u0026#39;\\n\u0026#39;` Альтернативный вариант преобразования в hex с od вместо xxd:\n| od -A n -t x1 | sed 's/ *//g' | tr -d '\\n'\nПояснения # При указании -cipher добавлять опцию -tls1_2 не нужно.\necho -n -e \u0026quot;\\x1e\u0026quot; \u0026ndash; добавление в psk_identity непечатного символа0x1e(Record Separator).\n*UserAgent* \u0026ndash; идентификатор по умолчанию для default console. При использовании named-консоли необходимо заменить *UserAgent* на Name этой консоли, указанное в конфиге bareos-dir.\nНапример, для консоли с именем \u0026ldquo;named_console\u0026rdquo;:\n-psk_identity \u0026quot;R_CONSOLE`echo -n -e \u0026quot;\\x1e\u0026quot;`named_console\u0026quot;\n-psk == hexadecimal от md5-хэша от пароля, указанного в конфиге (в этом примере пароль 30b5246d003966329927)\nПример вывода при успешном подключении: ","date":"11 февраля 2024","externalUrl":null,"permalink":"/posts/bareos-dir_openssl-s_client/","section":"Posts","summary":"","title":"Проверка возможности подключения к Bareos Director с openssl s_client","type":"posts"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/bash/","section":"Tags","summary":"","title":"Bash","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/kaspersky/","section":"Tags","summary":"","title":"Kaspersky","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/vmware/","section":"Tags","summary":"","title":"VMware","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/tags/vstack/","section":"Tags","summary":"","title":"Vstack","type":"tags"},{"content":"","date":"30 августа 2024","externalUrl":null,"permalink":"/","section":"Заметки вокруг ИТ","summary":"","title":"Заметки вокруг ИТ","type":"page"},{"content":" Подготовка рабочего окружения (OEL9) # В примере для взаимодействия с VMware Cloud Director будет использоваться утилита vcd-cli. Вместо неё можно использовать и ovftool.\ndnf install -y python3 qemu-img libguestfs guestfs-tools python -m ensurepip --upgrade pip install --user vcd-cli Подготовка ВМ в vcd # Для последующего скачивания виртуальную машину нужно развернуть в отдельном vApp.\nКонфигурация созданной ВМ должна соответствовать следующим параметрам:\n8 vCPU 16 GB RAM 200 GB HDD Guest OS: Red Hat Enterprise Linux 9 (64-bit) Boot Firmware: EFI EFI Secure Boot: Disabled В установщике есть проверка на соответствие этим требованиям к ресурсам. При несоответствии установку продолжить нельзя.\nНеобходимо произвести установку VA с ISO-образа и после установки загрузиться и пройти мастер первоначальной настройки с указанием любых параметров.\nЗагрузиться в single после установки невозможно -- учётная запись root заблокирована. Способ с `init=/bin/bash` также не работает. Выгрузка шаблона ВМ/vApp из vcd с vcd-cli # Логинимся в vcd\nvcd login \u0026lt;vcd_fqdn\u0026gt; \u0026lt;org\u0026gt; \u0026lt;user\u0026gt; Пример:\n$ vcd login vcloud.mycloud.com myorg my.username Password: my.username logged in, org: \u0026#39;myorg\u0026#39;, vdc: \u0026#39;vcd-nsxv\u0026#39; (Для информации) получаем список доступных в vDC vApps\nvcd vapp list Пример:\nisDeployed isEnabled memoryAllocationMB name numberOfCpus numberOfVMs ownerName status storageKB vdcName ------------ ----------- -------------------- --------------------------------------------- -------------- ------------- -------------- ----------- ----------- --------- false true 16384 ksmg-va-2107854 8 1 my.username POWERED_OFF 209715200 vdc-nsxv true true 81920 lab-itglobal-com-vapp 32 4 my.username MIXED 639631360 vdc-nsxv true true dr-vm-02-7e600f54-b3ec-4764-88ef-18311290564a 0 my.username POWERED_ON 0 vdc-nsxt true true 16384 tq-dmz-vapp 8 1 my.username POWERED_ON 20971520 vdc-nsxv true true 18432 tq-mgmt-vapp 10 2 my.username POWERED_ON 734003200 vdc-nsxv Скачиваем ранее развёрнутое vApp\nvcd vapp download \u0026lt;vapp_name\u0026gt; ./ Пример:\n$ vcd vapp download ksmg-va-2107854 ./ \u0026lt;Enabling download of Virtual Application...\u0026gt; download 1,335,374,336 of 1,335,374,336 bytes, 100% download 270,840 of 270,840 bytes, 100% property value ---------- --------------- file ksmg-va-2107854 size 1335664640 Модификация образа # Распаковываем шаблон (сделать это можно любым архиватором)\ntar -xvf ksmg-va-2107854 Примечание:\nThe qemu driver for VMDK does not support writes to the VMDK subformat (streamOptimized). This is a bug / shortcoming in qemu. The only workaround is to convert to a simpler format, eg. raw. \u0026ndash; поэтому уже на текущем этапе конвертируем vmdk в raw:\nqemu-img convert -p -f vmdk -O raw vm-95b6833a-e214-4994-aa4c-6f9a60034d5a-disk-0.vmdk ksmg-va-2107854.img (Для информации) получаем список имеющихся разделов и файловых систем:\nLIBGUESTFS_BACKEND=direct virt-filesystems -lh --uuid -a ksmg-va-2107854.img Пример:\nName Type VFS Label Size Parent UUID /dev/sda1 filesystem vfat - 498M - 542A-2139 /dev/sda2 filesystem ext2 - 466M - 82540b2f-5045-4ded-88c7-23ae6c5afd12 /dev/sda3 filesystem ext4 - 9,7G - 32701b3b-eae1-4f69-88bb-d881efefb636 /dev/sda4 filesystem ext4 - 24G - b0aa351a-5a82-4a45-8064-b9f186caaab0 /dev/sda5 filesystem ext4 - 39G - 39ffb068-7d45-4a87-bb57-08e6d2ecba55 /dev/sda6 filesystem ext4 - 97G - da2a721d-218c-4a0c-9593-fba4bfbc94ec /dev/sda7 filesystem ext4 - 12G - 0c8f6afb-de89-4fda-9276-2e2af1136d07 Переходим в режим суперпользователя\nsudo -i Создаём точку монтирования\nmkdir ksmg Монтируем все разделы с виртуального диска\nLIBGUESTFS_BACKEND=direct guestmount -a ksmg-va-2107854.img -i --rw ksmg mount --bind /dev ksmg/dev mount --bind /dev/pts ksmg/dev/pts mount --bind /proc ksmg/proc mount --bind /sys ksmg/sys Копируем настройки dns из текущего окружения\ncp /etc/resolv.conf ksmg/etc/ Меняем окружение\nchroot ksmg Добавляем в dracut драйверы virtio\necho \u0026#39;add_drivers+=\u0026#34;virtio_blk virtio_scsi virtio_net virtio_pci virtio_rng virtio_balloon nvme\u0026#34;\u0026#39; \u0026gt; /etc/dracut.conf.d/virtio.conf Выясняем версию ядра в образе ВМ:\nls /lib/modules/ 5.14.0-362.18.1.el9_3.0.1.x86_64\nГенерируем initramfs\ndracut -f -v -N \u0026#39;\u0026#39; 5.14.0-362.18.1.el9_3.0.1.x86_64 Проверяем наличие драйверов в initramfs\nlsinitrd /boot/initramfs-5.14.0-362.18.1.el9_3.0.1.x86_64.img | grep virtio Включаем репозитории Rocky Linux\ndnf config-manager --releasever 9.3 --enable baseos appstream Устанавливаем cloud-init\ndnf install -y cloud-init cloud-utils-growpart Активируем службы cloud-init\nsystemctl enable cloud-init cloud-init-local cloud-config cloud-final Добавляем настройки cloud-init datasources для vStack\ncat \u0026lt;\u0026lt; EOT \u0026gt; /etc/cloud/cloud.cfg.d/90_vStack.cfg datasource_list: [ \u0026#34;SmartOS\u0026#34;, \u0026#34;NoCloud\u0026#34; ] EOT Модифицируем скрипт /opt/kaspersky/ksmg-appliance-addon/bin/wizard, чтобы избежать запроса мастером первоначальной настройки уже переданных через cloud-init сетевых параметров\nsed -i -e \u0026#39;s/configure_network(widgets)$/#configure_network(widgets)\u0026#39; /opt/kaspersky/ksmg-appliance-addon/bin/wizard Удаляем open-vm-tools\ndnf --noautoremove remove open-vm-tools Выключаем репозитории:\ndnf config-manager --releasever 9.3 --disable baseos appstream echo \u0026#34;\u0026#34; \u0026gt; /etc/resolv.conf Очищаем историю\nhistory -c \u0026amp;\u0026amp; history -w Выходим из chroot и размонтируем разделы\nexit umount -R ksmg Сжимаем образ\nxz -0 -T 4 ./ksmg-va-2107854.img Подготовленный образ передаём вендору для добавления в кластер.\n","date":"30 августа 2024","externalUrl":null,"permalink":"/posts/import-ksmg-va-from-vcd-to-vstack/","section":"Posts","summary":"","title":"Подготовка образа Kaspersky Secure Mail Gateway 2.1-VA к импорту из VMware Cloud Director в vStack HCP","type":"posts"},{"content":"","date":"12 августа 2024","externalUrl":null,"permalink":"/tags/iscsi/","section":"Tags","summary":"","title":"Iscsi","type":"tags"},{"content":"","date":"12 августа 2024","externalUrl":null,"permalink":"/tags/lvm/","section":"Tags","summary":"","title":"Lvm","type":"tags"},{"content":"","date":"12 августа 2024","externalUrl":null,"permalink":"/tags/multipathd/","section":"Tags","summary":"","title":"Multipathd","type":"tags"},{"content":"","date":"12 августа 2024","externalUrl":null,"permalink":"/tags/vcd/","section":"Tags","summary":"","title":"Vcd","type":"tags"},{"content":"","date":"23 апреля 2024","externalUrl":null,"permalink":"/tags/losetup/","section":"Tags","summary":"","title":"Losetup","type":"tags"},{"content":"","date":"23 апреля 2024","externalUrl":null,"permalink":"/tags/mknod/","section":"Tags","summary":"","title":"Mknod","type":"tags"},{"content":" losetup - утилита управления loop-устройствами # Простой пример использования:\nМонтируем образ: sudo losetup -fR image.img Флаг -f (\u0026ldquo;find\u0026rdquo;) смонтирует образ в первое свободное обнаруженное в системе loop-устройство.\nФлаг -R (\u0026ldquo;recursive\u0026rdquo;) используется для сканирования образа на существующие в нём разделы и их последующего монтирования.\nПолучаем информацию о подключенных устройствах: losetup -a Пример вывода:\n/dev/loop0: []: (/home/user/image.img) Отключаем ранее подключенное устройство: sudo losetup -d /dev/loop0 На старых системах возможен вариант, когда флаг -R не работает, поскольку модуль loop.ko загружается с опцией по умолчанию max_part=0.\nУбедиться в этом можно командой:\ncat /sys/module/loop/parameters/max_part В этом случае, чтобы в /dev для loop-устройства отобразился, к примеру, существующий раздел loop0p1, соответствующий первому разделу смонтированного образа, последовательность действий будет такая:\nотключаем ранее подключенное устройство: sudo losetup -d /dev/loop0 выгружаем модуль: sudo modprobe -r loop загружаем с нужной опцией: sudo modprobe loop max_part=31 Чтобы эта настройка стала перманентной, необходимо добавить в /etc/modprobe.confили в новый файл в директории /etc/modprobe.d/ строку: options loop max_part=31\nповторно подключаем образ как loop-устройство: sudo losetup -f image.img проверяем наличие смонтированных разделов: lsblk Вывод команды:\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS loop0 7:0 0 200M 0 loop └─loop0p1 7:1 0 199M 0 part mknod - # https://www.oreilly.com/library/view/linux-device-drivers/0596000081/ch03s02.html\nolder: Character devices: 1 mem 2 pty 3 ttyp 4 ttyS 6 lp 7 vcs 10 misc 13 input 14 sound 21 sg 180 usb\nBlock devices: 2 fd 8 sd 11 sr 65 sd 66 sd newer: Character devices: 1 mem 4 /dev/vc/0 4 tty 4 ttyS 5 /dev/tty 5 /dev/console 5 /dev/ptmx 7 vcs 10 misc 13 input 14 sound 21 sg 81 video4linux 90 mtd 108 ppp 116 alsa 128 ptm 136 pts 180 usb 188 ttyUSB 189 usb_device 202 cpu/msr 203 cpu/cpuid 216 rfcomm 226 drm 234 media 235 mei 236 nvme-generic 237 nvme 238 aux 239 cec 240 binder 241 hidraw 242 ttyDBC 243 usbmon 244 wwan_port 245 bsg 246 watchdog 247 ptp 248 pps 249 lirc 250 rtc 251 dma_heap 252 dax 253 tpm 254 gpiochip 261 accel\nBlock devices: 7 loop 8 sd 9 md 11 sr 65 sd 66 sd 67 sd 68 sd 69 sd 70 sd 71 sd 128 sd 129 sd 130 sd 131 sd 132 sd 133 sd 134 sd 135 sd 252 zram 253 device-mapper 254 mdp 259 blkext together # Создаём блочное устройство\nmknod /dev/sdb b 7 500 Подключаем к созданному устройству образ как loop-устройство\nlosetup /dev/sdb image.img ","date":"23 апреля 2024","externalUrl":null,"permalink":"/posts/losetup-mknod/","section":"Posts","summary":"","title":"Монтирование raw-образа диска (img) как блочного устройства в linux","type":"posts"},{"content":"","date":"11 февраля 2024","externalUrl":null,"permalink":"/tags/bareos/","section":"Tags","summary":"","title":"Bareos","type":"tags"},{"content":"","date":"11 февраля 2024","externalUrl":null,"permalink":"/tags/openssl/","section":"Tags","summary":"","title":"Openssl","type":"tags"},{"content":"title: style: nestedList # TOC style (nestedList|inlineFirstLevel) minLevel: 0 # Include headings from the specified level maxLevel: 0 # Include headings up to the specified level includeLinks: true # Make headings clickable debugInConsole: false # Print debug info in Obsidian console С компрессией zfs # rc.local\nset -e \u0026lt;...\u0026gt; specnode=mdconfig -a -t swap -s 32G zpool create -o cachefile=none -m /zram zram-tmpfs $specnode zfs set compression=lz4 atime=off dedup=off zram-tmpfs Со стандартной компрессией # mdconfig -a -t swap -o compress -o reserve -s 512m -u 7 swapon /dev/md7 либо\nmount /dev/md7 /mnt/ramdrive Примечание-цитата из man mdconfig:\n-t type Select the type of the memory disk.\nmalloc Storage for this type of memory disk is allocated with alloc(9). This limits the size to the malloc bucket limit in the kernel. If the -o reserve option is not set, creating and filling a large malloc-backed memory disk is a very easy way to panic the system. \u0026lt;\u0026hellip;\u0026gt; swap Storage for this type of memory disk is allocated from buffer memory. Pages get pushed out to swap when the system is under memory pressure, otherwise they stay in the operating memory. Using swap backing is generally preferred instead of using malloc backing.\n","externalUrl":null,"permalink":"/posts/mdconfig-swap-in-ram-freebsd/","section":"Posts","summary":"","title":"","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]